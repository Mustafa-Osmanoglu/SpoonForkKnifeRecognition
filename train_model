import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D
from sklearn.utils import class_weight

# --- 1. Ayarlar ---
INPUT_SHAPE = (224, 224, 3)
BATCH_SIZE  = 16
EPOCHS      = 15
LR          = 1e-5
DATA_DIR    = "dataset"
MODEL_DIR   = "models"
MODEL_PATH  = os.path.join(MODEL_DIR, "best_model.h5")
CLASSES     = ["spoon", "fork", "knife"]

# --- 2. Model Tanımı (Transfer Learning + Head) ---
def build_model(input_shape, num_classes):
    base = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)
    base.trainable = False
    model = models.Sequential([
        base,
        GlobalAveragePooling2D(),
        layers.Dense(128, activation="relu"),
        layers.Dropout(0.4),
        layers.Dense(num_classes, activation="softmax")
    ])
    return model

# --- 3. Data Generators (augmentasyon + normalizasyon) ---
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    brightness_range=[0.8, 1.2],
    horizontal_flip=True
)
val_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(
    os.path.join(DATA_DIR, "train"),
    target_size=INPUT_SHAPE[:2],
    batch_size=BATCH_SIZE,
    class_mode="categorical"
)
val_gen = val_datagen.flow_from_directory(
    os.path.join(DATA_DIR, "val"),
    target_size=INPUT_SHAPE[:2],
    batch_size=BATCH_SIZE,
    class_mode="categorical"
)

# --- 4. Class Weights Hesaplama ---
y_train = train_gen.classes
cw = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train),
    y=y_train
)
class_weights = dict(enumerate(cw))

# --- 5. Callbacks Tanımlama ---
os.makedirs(MODEL_DIR, exist_ok=True)
es = EarlyStopping(
    monitor="val_loss", patience=5, restore_best_weights=True, verbose=1
)
mc = ModelCheckpoint(
    MODEL_PATH, monitor="val_loss", save_best_only=True, verbose=1
)
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1
)

# --- 6. Modeli Oluştur ve Derle ---
model = build_model(INPUT_SHAPE, len(CLASSES))
model.compile(
    optimizer=optimizers.Adam(learning_rate=LR),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)
model.summary()

# --- 7. Modeli Eğit ---
history = model.fit(
    train_gen,
    epochs=EPOCHS,
    validation_data=val_gen,
    callbacks=[es, mc, reduce_lr],
    class_weight=class_weights
)

# --- 8. Eğitim Grafikleri ---
acc      = history.history['accuracy']
val_acc  = history.history['val_accuracy']
loss     = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(len(acc))

plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(epochs_range, acc, label='Train Acc')
plt.plot(epochs_range, val_acc, label='Val Acc')
plt.legend(loc='lower right')
plt.title('Accuracy')

plt.subplot(1,2,2)
plt.plot(epochs_range, loss, label='Train Loss')
plt.plot(epochs_range, val_loss, label='Val Loss')
plt.legend(loc='upper right')
plt.title('Loss')

plt.tight_layout()
plt.savefig("training_curves_optimized.png")
plt.show()

print(f"\nBest model saved at: {MODEL_PATH}")
